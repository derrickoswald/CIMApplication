package ch.ninecode.mv

import java.text.SimpleDateFormat
import java.util.TimeZone

import scala.collection.mutable.HashMap
import scala.io.Source

import org.apache.spark.rdd.RDD
import org.apache.spark.sql.SparkSession
import org.apache.spark.storage.StorageLevel
import org.slf4j.Logger
import org.slf4j.LoggerFactory

import ch.ninecode.cim.CIMNetworkTopologyProcessor
import ch.ninecode.cim.CIMRDD
import ch.ninecode.gl.GLMEdge
import ch.ninecode.gl.GridLABD
import ch.ninecode.gl.TransformerSet
import ch.ninecode.gl.Transformers
import ch.ninecode.model.BaseVoltage
import ch.ninecode.model.ConductingEquipment
import ch.ninecode.model.Element
import ch.ninecode.model.Terminal
import ch.ninecode.model.TopologicalNode

case class MediumVoltage (session: SparkSession, options: MediumVoltageOptions)
extends CIMRDD
with Serializable
{
    if (options.verbose)
        org.apache.log4j.LogManager.getLogger ("ch.ninecode.mv.MediumVoltage").setLevel (org.apache.log4j.Level.INFO)
    implicit val spark: SparkSession = session
    implicit val log: Logger = LoggerFactory.getLogger (getClass)

    // for dates without time zones, the timezone of the machine is used:
    //    date +%Z
    // timezone can be set on each node of the cluster with:
    //    dpkg-reconfigure tzdata
    // then choose Europe and then choose Zürich
    //
    // all dates generated by this program include the time zone
    val use_utc = true
    val date_format = new SimpleDateFormat ("yyyy-MM-dd HH:mm:ss z")
    if (use_utc)
        date_format.setTimeZone (TimeZone.getTimeZone ("UTC"))

    def run (): Long =
    {
        val start = System.nanoTime ()

        // determine transformer list if any
        val trafos = if ("" != options.trafos)
            // do all transformers listed in the file
            Source.fromFile (options.trafos, "UTF-8").getLines ().filter (_ != "").toArray
        else
            null
        if ((null != trafos) && (0 == trafos.length))
        {
            log.error  ("no transformers to process")
            sys.exit (1)
        }

        // read the file
        val reader_options = new HashMap[String, String] ()
        reader_options ++= options.cim_reader_options
        reader_options.put ("path", options.files.mkString (","))
        reader_options.put ("ch.ninecode.cim.make_edges", "false")
        reader_options.put ("ch.ninecode.cim.do_join", "false")
        reader_options.put ("ch.ninecode.cim.do_topo", "false")
        reader_options.put ("ch.ninecode.cim.do_topo_islands", "false")
        val elements = session.read.format ("ch.ninecode.cim").options (reader_options).load (options.files:_*)
        if (-1 != session.sparkContext.master.indexOf ("sandbox")) // are we in development
            elements.explain
        else
            log.info (elements.count () + " elements")

        val read = System.nanoTime ()
        log.info ("read: " + (read - start) / 1e9 + " seconds")

        val storage_level = options.cim_reader_options.find (_._1 == "StorageLevel") match
        {
            case Some ((_, storage)) => StorageLevel.fromString (storage)
            case _ => StorageLevel.fromString ("MEMORY_AND_DISK_SER")
        }

        // identify topological nodes if necessary
        val tns = session.sparkContext.getPersistentRDDs.filter(_._2.name == "TopologicalNode")
        if (tns.isEmpty || tns.head._2.isEmpty)
        {
            val ntp = new CIMNetworkTopologyProcessor (session, storage_level, force_retain_switches = true, force_retain_fuses = false)
            val ele = ntp.process (identify_islands = true)
            log.info (ele.count () + " elements")
        }

        val topo = System.nanoTime ()
        log.info ("topology: " + (topo - read) / 1e9 + " seconds")

        val _transformers = new Transformers (session, storage_level)
        val tdata = _transformers.getTransformerData (topological_nodes = true)

        // feeder service area calculations
        val feeder = Feeder (session, options.storage)
        val nodes_feeders = feeder.getFeederMap.filter (_._2 != null) // (nodeid, feederid)

        // get a map of voltages
        // ToDo: fix this 1kV multiplier on the voltages
        val voltages = get("BaseVoltage").asInstanceOf[RDD[BaseVoltage]].map(v ⇒ (v.id, v.nominalVoltage * 1000.0)).collectAsMap()
        val ff: RDD[(String, TopologicalNode)] = nodes_feeders.join (get[TopologicalNode].keyBy (_.id)).values
        val nodes = ff.keyBy (_._2.id).leftOuterJoin (feeder.feederNodes).values
                        .map (x ⇒ (x._1._1, FeederNode.toFeederNode (x._2.map (List(_)).orNull, x._1._2.id, voltages.getOrElse (x._1._2.BaseVoltage, 0.0))))

        // get equipment with nodes & terminals
        val gg: RDD[(String, Iterable[(String, Terminal)])] = get[Terminal].map (x ⇒ (x.ConductingEquipment, (x.TopologicalNode, x))).groupByKey // (equipmentid, [(nodeid, terminal)])
        // eliminate 0Ω links
        val hh = gg.filter (x ⇒ x._2.groupBy (_._1).size > 1)
        val eq: RDD[(Iterable[(String, Terminal)], Element)] = get[ConductingEquipment].keyBy (_.id).join (get[Element]("Elements").keyBy (_.id)).map (x ⇒ (x._1, x._2._2)) // (elementid, Element)
            .join (hh).values.map (_.swap) // ([(nodeid, terminal)], Element)
            // eliminate edges with only one end
            .filter (x ⇒ (x._1.size > 1) && x._1.map (_._1).forall (_ != null)) // ([(nodeid, terminal)], Element)
        // index by feeder
        val jj: RDD[(String, (Iterable[(String, Terminal)], Element))] = eq.flatMap (x ⇒ x._1.map (y ⇒ (y._1, x))).join (nodes_feeders).values.map (_.swap) // (feederid, ([(nodeid, Terminal)], Element)
        // ToDo: is it better to groupBy feeder first?
        val kk: RDD[Iterable[(String, (Iterable[(String, Terminal)], Element))]] = jj.keyBy (_._2._1.map (_._1).toArray.sortWith (_ < _).mkString ("_")).groupByKey.values // [(feederid, ([(nodeid, Terminal)], Element)]
        // make one edge for each unique feeder it's in
        val ll: RDD[(String, Iterable[(Iterable[(String, Terminal)], Element)])] = kk.flatMap (x ⇒ x.map (_._1).toArray.distinct.map (y ⇒ (y, x.map (_._2))))

        // make edges
        // ToDo: fix this collect
        val transformers = tdata.groupBy (_.terminal1.TopologicalNode).values.map (_.toArray).map (TransformerSet (_)).collect
        def make_edge (transformers: Array[TransformerSet]) (args: Iterable[(Iterable[(String, Terminal)], Element)]): GLMEdge =
        {
            // the terminals may be different for each element, but their TopologicalNode values are the same, so use the head
            val id_cn_1 = args.head._1.head._2.TopologicalNode
            val id_cn_2 = args.head._1.tail.head._2.TopologicalNode
            AbgangKreis.toGLMEdge (transformers) (args.map (_._2), id_cn_1, id_cn_2)
        }
        val edges = ll.map (x ⇒ (x._1, make_edge (transformers) (x._2))).cache

        val feeders: RDD[FeederArea] = nodes.groupBy (_._1).map (x ⇒ (x._1, x._2.map (_._2))).join (edges.groupByKey).map (x ⇒ FeederArea (x._1, x._2._1, x._2._2))

        def generate (gridlabd: GridLABD, area: FeederArea): Int =
        {
            val generator = MvGLMGenerator (one_phase = true, temperature = options.temperature, date_format = date_format, area)
            gridlabd.export (generator)
            log.info (area.feeder)
            1
        }
        val gridlabd = new GridLABD (session, topological_nodes = true, one_phase = !options.three, storage_level = storage_level, workdir = options.workdir)
        val count = feeders.map (generate (gridlabd, _)).sum.longValue

        /*
        def node_maker (rdd: RDD[(String, Iterable[(String, (Terminal, Element, BaseVoltage))])]): RDD[(String, GLMNode)] =
        {
            val ss = rdd.keyBy (_._2.head._2._2.id).join (get[ConductingEquipment].keyBy (_.id)).values.map (x ⇒ (x._1._1, x._1._2.map (y ⇒ (y._1, (y._2._1, x._2, y._2._3)))))
            ss.map (args ⇒ (args._2.head._1, GLMNode.toGLMNode (args._2.map (_._2._2), args._1, args._2.head._2._3.nominalVoltage * 1000.0)))
        }



        // toGLMNode (elements: Iterable[Element], id: String, nominal_voltage: Double)
        // toGLMEdge (elements: Iterable[Element], cn1: String, cn2: String)

        val island_helper = new Island (session, storage_level)
        val graph_stuff: (Nodes, Edges) = island_helper.queryNetwork (mv_feeders_islands, node_maker, edge_maker) // ([nodes], [edges])
        val areas = graph_stuff._1.groupByKey.join (graph_stuff._2.groupByKey).map (x ⇒ FeederArea (x._1, x._2._1, x._2._2)).cache
        println (areas.map (x ⇒ "%s: %s nodes, %s edges".format (x.feeder, x.nodes.size, x.edges.size)).collect.mkString ("\n"))
        def generate (gridlabd: GridLABD, area: FeederArea): Unit =
        {
            val generator = MvGLMGenerator (one_phase = true, temperature = options.temperature, date_format = date_format, area)
            gridlabd.export (generator)
        }
        val gridlabd = new GridLABD (session, topological_nodes = true, one_phase = !options.three, storage_level = storage_level, workdir = options.workdir)
        areas.foreach (generate (gridlabd, _))
*/

        /*
        // prepare the initial graph edges and nodes
        val (xedges, xnodes) = gridlabd.prepare ()

        val _transformers = new Transformers (session, storage_level)
        val tdata = _transformers.getTransformerData (topological_nodes = true)

        // determine the set of transformers to work on
        /**
         * The name of the node associated with the high voltage terminal.
         * @param pair The transformer information and topological node pair to get the island for.
         * @return The name of the TopologicalNode or ConnectivityNode.
         */
        def lv_island_name (pair: (TData, TopologicalNode)): (String, TData) =
        {
            val transformer = pair._1
            val island = pair._2.TopologicalIsland
            (island, transformer)
        }

        val tnodes = session.sparkContext.getPersistentRDDs.filter(_._2.name == "TopologicalNode").head._2.asInstanceOf[RDD[TopologicalNode]]
        // do all high voltage power transformer (low voltage) islands
        val islands = if (null != trafos)
        {
            val selected = tdata.filter (x => trafos.contains (x.transformer.id)).keyBy (_.node1).join (tnodes.keyBy (_.id)).values.map (lv_island_name).groupByKey
            selected.values.map (_.groupBy (_.terminal1.TopologicalNode).values.map (_.toArray).map (TransformerSet (_)))
        }
        else
        {
            // get the high voltage transformers grouped by low voltage TopologicalIsland
            val hochspannung = tdata.filter (td => (td.voltage1 > 0.4) || (td.voltage0 > 16.0)).keyBy (_.node1).join (tnodes.keyBy (_.id)).values.map (lv_island_name).groupByKey
            // create a TransformerSet for each different low voltage TopologicalNode
            hochspannung.values.map (_.groupBy (_.terminal1.TopologicalNode).values.map (_.toArray).map (TransformerSet (_)))
        }

        // determine the list of low voltage transformer sets
        val lv = tdata.filter (_.voltage1 <= 0.4).groupBy (_.terminal1.TopologicalNode).values.map (_.toArray).map (TransformerSet (_))

        val prepare = System.nanoTime ()
        log.info ("prepare: " + (prepare - topo) / 1e9 + " seconds")

        log.info ("" + islands.count + " island(s) to process")

        val tasks = islands.collect
        println (tasks.map (_.head.transformer_name).mkString ("\n"))
        def doit (transformers: Iterable[TransformerSet]): Int =
        {
            // get the transformer low voltage pin topological node
            val nothing = PreNode ("", 0.0)
            val id = nothing.vertex_id (transformers.head.node1)
            // trace everything from that pin
            val initial = Graph.apply[PreNode, PreEdge] (xnodes, xedges, nothing, storage_level, storage_level)
            val starting_nodes = Array[VertexId] (id)
            val trace = Trace (initial)
            val (nodes, edges) = trace.run (starting_nodes)
            // form the USTKreis data packet to send to the executor
            val ynodes = nodes.collect
            val yedges = edges.collect
            val ust = USTKreis (transformers.toArray, ynodes, yedges, lv.collect)
            println (ust.trafokreis_key + " traced " + ynodes.length + " nodes and " + yedges.length + " edges")

            // create the GLMGenerator
            val generator = MediumVoltageGLMGenerator (!options.three, date_format, ust)
            gridlabd.export (generator)
            1
        }
        val done = tasks.map (doit)
        println (done.length.toString + " transformers processed")

        val calculate = System.nanoTime ()
        log.info ("calculate: " + (calculate - prepare) / 1e9 + " seconds")

        islands.count
        */

        count
    }
}
